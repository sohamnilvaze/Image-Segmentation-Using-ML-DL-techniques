{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VSvIaJuoYpY-"},"outputs":[],"source":["import numpy as np\n","import time\n","import os\n","import matplotlib.pyplot as plt\n","import cv2\n","import tensorflow_datasets as tfds\n","import tensorflow as tf\n","from tensorflow import keras\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.layers import Convolution2D, BatchNormalization, ReLU, LeakyReLU, Add, Activation\n","from tensorflow.keras.layers import GlobalAveragePooling2D, AveragePooling2D, UpSampling2D\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3678,"status":"ok","timestamp":1733288342267,"user":{"displayName":"Tanmayi Sulakhe","userId":"00222610342895436167"},"user_tz":-330},"id":"CsMFeIU9TnZ4","outputId":"0d377367-b162-4052-f91d-b3592298dd95"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","['geckodriver', 'geckodriver-v0.34.0-linux64.tar.gz', 'gittoken.txt', 'hackathon_coep', 'final_Project', 'CN', 'SE', 'Colab Notebooks', 'dataset']\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","print(os.listdir('/content/drive/MyDrive'))\n","\n","\n","# # Step 1: Specify the directory containing the extracted Cityscapes data\n","# data_dir = '/content/drive/MyDrive/dataset'  # Replace with your actual path\n","\n","# # Step 2: Manually register the Cityscapes data with tfds\n","# # Assuming tfds version >= 4.4.0 for register_from_path function\n","# tfds.register_from_path('cityscapes', data_dir)\n","\n","\n","# # Step 3: Now load the dataset\n","# dataset = tfds.load('cityscapes', split='train')\n","# color_map = dataset.info.features['label'].int2str\n","# print(color_map)\n","\n","\n","train_data_folder = '/content/drive/MyDrive/dataset/train'\n","valid_data_folder = '/content/drive/MyDrive/dataset/val'\n","# print(os.listdir(train_data_folder))\n","# print(os.listdir(valid_data_folder))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AA97rGzUY9k8"},"outputs":[],"source":["# Load a subset of training and validation data\n","from sklearn.model_selection import train_test_split\n","\n","\n","num_train_samples = 2000  #more the train samples better the model, use about 500 - 700 later\n","num_valid_samples = 70   # mazhe valid samples train samples peksha kami pahijet, pan 50-100 chalel\n","\n","def load_image_mask_subset(path, num_samples=None):\n","    file_names = os.listdir(path)[:num_samples]\n","    image_list, mask_list = [], []\n","    for file_name in file_names:\n","        image = cv2.imread(os.path.join(path, file_name))\n","        image = cv2.normalize(image, None, 0, 1, cv2.NORM_MINMAX, cv2.CV_32F)\n","        image = image[:, :, ::-1]\n","\n","        # Convert Color Space (BGR to RGB): Since OpenCV loads images in BGR format by default, this reverses the color channels to RGB format (standard in deep learning libraries like TensorFlow and PyTorch).\n","\n","        image_list.append(image[:, :256])  # All image masks are in 256*256 format\n","\n","        # the input image contains both the image and mask concatenated side-by-side in a single file (where the full width would be 512 pixels: 256 for the image and 256 for the mask).\n","\n","        mask_list.append(np.reshape(image[:, 256:], (256 * 256 * 3)))  # All image masks are in 256*256 format\n","\n","\n","        del image\n","    del file_names\n","    return image_list, mask_list\n","\n","train_images, train_masks = load_image_mask_subset(train_data_folder, num_samples=num_train_samples)\n","valid_images, valid_masks = load_image_mask_subset(valid_data_folder, num_samples=num_valid_samples)\n","\n","train_images, test_images, train_masks, test_masks = train_test_split(train_images, train_masks, test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M85oGkJMadZx"},"outputs":[],"source":["def convolutional_block(input_tensor, filters, block_identifier):\n","    # Dilated convolution block\n","    block_name = 'block_' + str(block_identifier) + '_'\n","    filter1, filter2, filter3 = filters\n","    skip_connection = input_tensor\n","\n","    # Block A\n","    input_tensor = Convolution2D(filters=filter1, kernel_size=(1, 1), dilation_rate=(1, 1),\n","                      padding='same', kernel_initializer='he_normal', name=block_name + 'a')(input_tensor)\n","    input_tensor = BatchNormalization(name=block_name + 'batch_norm_a')(input_tensor)\n","    input_tensor = LeakyReLU(alpha=0.2, name=block_name + 'leakyrelu_a')(input_tensor)\n","\n","    # Block B\n","    input_tensor = Convolution2D(filters=filter2, kernel_size=(3, 3), dilation_rate=(2, 2),\n","                      padding='same', kernel_initializer='he_normal', name=block_name + 'b')(input_tensor)\n","    input_tensor = BatchNormalization(name=block_name + 'batch_norm_b')(input_tensor)\n","    input_tensor = LeakyReLU(alpha=0.2, name=block_name + 'leakyrelu_b')(input_tensor)\n","\n","    # Block C\n","    input_tensor = Convolution2D(filters=filter3, kernel_size=(1, 1), dilation_rate=(1, 1),\n","                      padding='same', kernel_initializer='he_normal', name=block_name + 'c')(input_tensor)\n","    input_tensor = BatchNormalization(name=block_name + 'batch_norm_c')(input_tensor)\n","\n","    # Skip convolutional block for residual\n","    skip_connection = Convolution2D(filters=filter3, kernel_size=(3, 3), padding='same', name=block_name + 'skip_conv')(skip_connection)\n","    skip_connection = BatchNormalization(name=block_name + 'batch_norm_skip_conv')(skip_connection)\n","\n","    # Block C + Skip Convolution\n","    input_tensor = Add(name=block_name + 'add')([input_tensor, skip_connection])\n","    input_tensor = ReLU(name=block_name + 'relu')(input_tensor)\n","    return input_tensor\n","\n","\n","\n","def base_convolutional_block(input_layer):\n","    # Base convolutional block to obtain input image feature maps\n","\n","    # Base Block 1\n","    base_result = convolutional_block(input_layer, [32, 32, 64], '1')\n","\n","    # Base Block 2\n","    base_result = convolutional_block(base_result, [64, 64, 128], '2')\n","\n","    # Base Block 3\n","    base_result = convolutional_block(base_result, [128, 128, 256], '3')\n","\n","    return base_result\n","\n","def pyramid_pooling_module(input_layer):\n","    # Pyramid pooling module\n","    base_result = base_convolutional_block(input_layer)\n","\n","    # Red Pixel Pooling\n","    red_result = GlobalAveragePooling2D(name='red_pool')(base_result)\n","    red_result = tf.keras.layers.Reshape((1, 1, 256))(red_result)\n","    red_result = Convolution2D(filters=64, kernel_size=(1, 1), name='red_1_by_1')(red_result)\n","    red_result = UpSampling2D(size=256, interpolation='bilinear', name='red_upsampling')(red_result)\n","\n","    # Yellow Pixel Pooling\n","    yellow_result = AveragePooling2D(pool_size=(2, 2), name='yellow_pool')(base_result)\n","    yellow_result = Convolution2D(filters=64, kernel_size=(1, 1), name='yellow_1_by_1')(yellow_result)\n","    yellow_result = UpSampling2D(size=2, interpolation='bilinear', name='yellow_upsampling')(yellow_result)\n","\n","    # Blue Pixel Pooling\n","    blue_result = AveragePooling2D(pool_size=(4, 4), name='blue_pool')(base_result)\n","    blue_result = Convolution2D(filters=64, kernel_size=(1, 1), name='blue_1_by_1')(blue_result)\n","    blue_result = UpSampling2D(size=4, interpolation='bilinear', name='blue_upsampling')(blue_result)\n","\n","    # Green Pixel Pooling\n","    green_result = AveragePooling2D(pool_size=(8, 8), name='green_pool')(base_result)\n","    green_result = Convolution2D(filters=64, kernel_size=(1, 1), name='green_1_by_1')(green_result)\n","    green_result = UpSampling2D(size=8, interpolation='bilinear', name='green_upsampling')(green_result)\n","\n","    # Final Pyramid Pooling\n","    return tf.keras.layers.concatenate([base_result, red_result, yellow_result, blue_result, green_result])\n","\n","\n","def pyramid_based_conv(input_layer):\n","    result = pyramid_pooling_module(input_layer)\n","    result = Convolution2D(filters=3, kernel_size=3, padding='same', name='last_conv_3_by_3')(result)\n","    result = BatchNormalization(name='last_conv_3_by_3_batch_norm')(result)\n","    result = Activation('sigmoid', name='last_conv_relu')(result)\n","    result = tf.keras.layers.Flatten(name='last_conv_flatten')(result)\n","    return result\n","\n","input_layer = tf.keras.Input(shape=np.squeeze(train_images[0]).shape, name='input')\n","output_layer = pyramid_based_conv(input_layer)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7BCs3eY_WH-E"},"outputs":[],"source":["def pyramid_based_conv(input_layer):\n","    result = pyramid_pooling_module(input_layer)\n","    result = Convolution2D(filters=3, kernel_size=3, padding='same', name='last_conv_3_by_3')(result)\n","    result = BatchNormalization(name='last_conv_3_by_3_batch_norm')(result)\n","    result = Activation('sigmoid', name='last_conv_relu')(result)\n","    result = tf.keras.layers.Flatten(name='last_conv_flatten')(result)\n","    return result\n","\n","input_layer = tf.keras.Input(shape=np.squeeze(train_images[0]).shape, name='input')\n","output_layer = pyramid_based_conv(input_layer)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"mfKtfzosWIy6","outputId":"9df6201f-debd-40b5-d997-f2ee34e9c25e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","5/5 [==============================] - ETA: 0s - loss: 0.0720  "]},{"ename":"ValueError","evalue":"Expected input data to be non-empty.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-f1d225447d05>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#atta parenta 0.01 best hota\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m history = model.fit(np.array(train_images,dtype='float16'),np.array(train_masks,dtype='float16'),\n\u001b[0m\u001b[1;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           epochs=50,steps_per_epoch=5,verbose=1,batch_size=8) # increase epochs to minimun 50 and steps per epoch to minimum 40 for better model if you have resources\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected input data to be non-empty.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     def _configure_dataset_and_inferred_steps(\n","\u001b[0;31mValueError\u001b[0m: Expected input data to be non-empty."]}],"source":["model = tf.keras.Model(inputs=input_layer, outputs=output_layer)\n","\n","model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= 0.01),loss='mse')   #atta parenta 0.01 best hota\n","history = model.fit(np.array(train_images,dtype='float16'),np.array(train_masks,dtype='float16'),\n","          validation_data=(np.array(valid_images,dtype='float16'),np.array(valid_masks,dtype='float16')),\n","          epochs=50,steps_per_epoch=5,verbose=1,batch_size=8) # increase epochs to minimun 50 and steps per epoch to minimum 40 for better model if you have resources"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tF1AftPsk9rB"},"outputs":[],"source":["# After training the model\n","model.save('/content/drive/MyDrive/my_model.h5')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJlxbes0ZjN5"},"outputs":[],"source":["# Later, you can load the model like this\n","from tensorflow.keras.models import load_model\n","model = load_model('/content/drive/MyDrive/my_model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DsXZ9M2fWYPC"},"outputs":[],"source":["# Plot Loss vs. Accuracy\n","import matplotlib.pyplot as plt\n","plt.figure(figsize=(10, 4))\n","\n","# Plot Training vs. validation Loss\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['loss'], label='Training Loss')\n","plt.plot(history.history['val_loss'], label='Validation Loss')\n","plt.title('Training vs. Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hu7KjnZnWcXC"},"outputs":[],"source":["# model evaluation based on comparison\n","def plot_imgs(img,mask,pred):\n","    mask = np.reshape(mask,(256,256,3))\n","    pred = np.reshape(pred,(256,256,3))\n","    fig,(ax1,ax2,ax3) = plt.subplots(1,3,figsize=(15,10))\n","    ax1.imshow(img)\n","    ax1.axis('off')\n","    ax2.imshow(mask)\n","    ax2.axis('off')\n","    ax3.imshow(pred)\n","    ax3.axis('off')\n","pred_masks = model.predict(np.array(valid_images,dtype='float16'))\n","print('-------------Input---------------Actual mask--------------Predicted mask-------')\n","for i in range(1):\n","    x = np.random.randint(0,10,size=1)[0]\n","    plot_imgs(valid_images[x],valid_masks[x],pred_masks[x])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nv468Q0glwtL"},"outputs":[],"source":["test_data_folder = '/content/drive/MyDrive/dataset/test'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZClz6gxRlyaW"},"outputs":[],"source":["# def load_test_data(path, num_samples=None):\n","#     file_names = os.listdir(path)[:num_samples]\n","#     image_list, mask_list = [], []\n","#     for file_name in file_names:\n","#         image = cv2.imread(os.path.join(path, file_name))\n","#         image = cv2.normalize(image, None, 0, 1, cv2.NORM_MINMAX, cv2.CV_32F)\n","#         image = image[:, :, ::-1]\n","\n","#         image_list.append(image[:, :256])  # All image masks are in 256*256 format\n","#         mask_list.append(np.reshape(image[:, 256:], (256 * 256 * 3)))  # All image masks are in 256*256 format\n","\n","#         del image\n","#     return image_list, mask_list\n","\n","# test_images, test_masks = load_test_data(test_data_folder, num_samples=40)  # Adjust number of test samples\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nbERtD1Il1ks"},"outputs":[],"source":["test_pred_masks = model.predict(np.array(test_images, dtype='float16'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1MY80smEl3PM"},"outputs":[],"source":["# Test the model on test data\n","def plot_test_imgs(img, mask, pred):\n","    mask = np.reshape(mask, (256, 256, 3))\n","    pred = np.reshape(pred, (256, 256, 3))\n","    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 10))\n","    ax1.imshow(img)\n","    ax1.axis('off')\n","    ax2.imshow(mask)\n","    ax2.axis('off')\n","    ax3.imshow(pred)\n","    ax3.axis('off')\n","\n","# Visualize a random test image\n","for i in range(1):\n","    x = np.random.randint(0, len(test_images), size=1)[0]\n","    plot_test_imgs(test_images[x], test_masks[x], test_pred_masks[x])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dh-zYS3Ll4tK"},"outputs":[],"source":["test_loss = model.evaluate(np.array(test_images, dtype='float16'), np.array(test_masks, dtype='float16'))\n","print(\"Test Loss:\", test_loss)\n"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[{"file_id":"1HlfGQyBt1-qNTVrH34KU8IIf824VAthH","timestamp":1735451143907}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}